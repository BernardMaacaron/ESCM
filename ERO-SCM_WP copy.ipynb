{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6d126ffc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from brian2 import *\n",
    "# set_device('cpp_standalone') # for faster execution - builds a standalone C++ program\n",
    "\n",
    "import NeuronEquations\n",
    "import BrianHF\n",
    "import numpy as np\n",
    "\n",
    "from bimvee.importAe import importAe\n",
    "from EvCamDatabase import *\n",
    "\n",
    "import os\n",
    "import gc\n",
    "import time\n",
    "\n",
    "# TODO XXX: Turn all lists into numpy arrays for the sake of memory efficiency"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c1c0cc6",
   "metadata": {},
   "source": [
    "### 0. Importing the data using bimvee"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f3dc1209",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'filePathOrName': 'InputData/h36m_sample/cam2_S1_Directions/ch0dvs'}\n",
      "{'filePathOrName': 'InputData/h36m_sample/cam2_S1_Directions/ch0dvs'}\n",
      "importIitYarp trying path: InputData/h36m_sample/cam2_S1_Directions/ch0dvs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 32375/32375 [00:07<00:00, 4395.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Examining info.log: InputData/h36m_sample/cam2_S1_Directions/ch0dvs/info.log\n"
     ]
    }
   ],
   "source": [
    "# XXX: Extract the event stream using bimvee - needs refactoring to be more general\n",
    "grid_width, grid_height= IDNW['width'], IDNW['height']\n",
    "inputPath = 'h36m_sample/cam2_S1_Directions/ch0dvs'\n",
    "events = importAe(filePathOrName=os.path.join('InputData',inputPath))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "11440073",
   "metadata": {},
   "outputs": [],
   "source": [
    "eventStream = next(BrianHF.find_keys(events, 'dvs'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "1aea5bd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# grid_width, grid_height= DAVIS_346B['width'], DAVIS_346B['height']\n",
    "# inputPath = 'MVSEC_short_outdoor'\n",
    "# events = importAe(filePathOrName=os.path.join('InputData',inputPath))\n",
    "# try:\n",
    "#     eventStream = events[0]['data']['left']['dvs']\n",
    "# except:\n",
    "#     eventStream = events[0]['data']['right']['dvs']\n",
    "# eventStream.popitem()\n",
    "# print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93bd1f3c",
   "metadata": {},
   "source": [
    "## Steps for the setting up the network:\n",
    "1. Generate the input spikes\n",
    "2. Set the parameters for the Simulation and Network (Neurons, Synapses, etc.)\n",
    "3. Prepare the directory structure for saving the results\n",
    "4. Create the neuron group(s)\n",
    "5. Create the synapses\n",
    "6. Connect the synapses\n",
    "7. Define the weights of the synapses\n",
    "8. Set up monitors according to need\n",
    "9. Run the simulation\n",
    "10. (Optional) Visualize the results\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dfa559a",
   "metadata": {},
   "source": [
    "### 1. Generate the input spikes from the event stream\n",
    "###### Brian Simulation Scope"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "553dd49b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting the event data...\n",
      "Polarity is ignored. All events are extracted.\n",
      "Selecting a percentage of the spikes at regular intervals... Percentage:  100.0 %\n",
      "The maximum x index 639 while the width is 640\n",
      "The maximum y index 479 while the height is 480\n",
      "The x, y, and timestamp indices are equal, the data is correct.\n",
      "Checking for duplicate pairs...\n",
      "Duplicate pairs found. Total Number of duplicates: 822\n",
      "Total number of pairs/spikes after removing duplicates: 5434099 pairs.\n",
      "The maximum timestamp (scaled) 32266.998 ms.\n",
      "The recommended simulation time (scaled) is 32267.0 ms.\n",
      "The minimum time step (scaled) is 0.499999999996362 ms.\n",
      "The recommended clock time step (scaled) is 0.5 ms.\n",
      "Input event stream successfully converted to spike trains\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# HACK XXX: The input is now not in real time, must be fixed eventually to process real time event data\n",
    "# IMPORTANT NOTE: Output is float, so we need to convert to Quantities (i.e give them units)\n",
    "\n",
    "# Simulation Parameters\n",
    "defaultclock.dt = 0.5*ms\n",
    "samplePerc = 1.0\n",
    "SaveNumpyFrames = False\n",
    "GenerateGIFs = False\n",
    "GenerateVideos = True\n",
    "\n",
    "GenerateInputVisuals = False\n",
    "GenerateOutputVisuals = False\n",
    "\n",
    "simTime, clockStep, inputSpikesGen = BrianHF.event_to_spike(eventStream, grid_width, grid_height,\n",
    "                                                            dt = defaultclock.dt, timeScale = 1.0, samplePercentage=samplePerc)\n",
    "# defaultclock.dt = clockStep*ms\n",
    "print(\"Input event stream successfully converted to spike trains\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2657cbf5",
   "metadata": {},
   "source": [
    "### 2. Set the parameters for the Simulation and Network (Neurons, Synapses, etc.)\n",
    "Parameter values can be tuned per namespace (this is done for clarity purposes)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "9376017c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOTE: The values are unitless for now, time constants are in ms simply to be able to tune to the simulation clock\n",
    "\n",
    "# Neuron Parameters\n",
    "N_Neurons = grid_width * grid_height    # Number of neurons\n",
    "\n",
    "Neuron_Params = {'tau': 0.2*ms, 'vt': 0.1, 'vr': 0.0, 'P': 0, 'incoming_spikes': 0, 'method_Neuron': 'exact'}\n",
    "tau = Neuron_Params['tau']\n",
    "vt = Neuron_Params['vt']\n",
    "vr = Neuron_Params['vr']\n",
    "P = Neuron_Params['P']\n",
    "incoming_spikes = Neuron_Params['incoming_spikes']\n",
    "\n",
    "Eqs_Neurons = NeuronEquations.EQ_SCM_IF    # Neurons Equation\n",
    " \n",
    "# Synapse Parameters\n",
    "'''\n",
    "Neighborhood Size (num_Neighbors) - Affects the number of neighbors a central neuron based on the L1 Distance\n",
    "Neighboring Neurons --> (abs(X_pre - X_post) <= Num_Neighbours  and abs(Y_pre - Y_post) <= Num_Neighbours)\n",
    "'''\n",
    "Syn_Params = {'Num_Neighbours' : 20, 'beta': 0.5, 'W_Exc': 6.0, 'W_Inh': -0.5, 'method_Syn': 'exact'}\n",
    "Num_Neighbours = Syn_Params['Num_Neighbours']\n",
    "beta = Syn_Params['beta']\n",
    "W_Exc = Syn_Params['W_Exc']\n",
    "W_Inh = Syn_Params['W_Inh']\n",
    "\n",
    "# Generate the dictionary of parameters for the network\n",
    "networkParams = {**Neuron_Params, **Syn_Params, 'Sim_Clock': defaultclock.dt, 'Sample_Perc': samplePerc}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bf75640",
   "metadata": {},
   "source": [
    "### 3. Prepare the directory structure for saving the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "3f49d544",
   "metadata": {},
   "outputs": [],
   "source": [
    "resultPath = 'SimulationResults'\n",
    "inputStr = BrianHF.filePathGenerator('SCM_LIF_IN', networkParams).replace(\" \", \"\")\n",
    "outputStr = BrianHF.filePathGenerator('SCM_LIF_OUT', networkParams).replace(\" \", \"\")\n",
    "\n",
    "# Create the folder if it doesn't exist\n",
    "if not os.path.exists(resultPath):\n",
    "    os.makedirs(resultPath)\n",
    "\n",
    "logPath = os.path.join('YarpSpikeLog', outputStr)\n",
    "# Create the subfolders if they don't exist\n",
    "subfolders = ['spikeFrames', 'numpyFrames', 'gifs', 'videos', logPath]\n",
    "for subfolder in subfolders:\n",
    "    subfolderPath = os.path.join(resultPath, inputPath, subfolder)\n",
    "    if not os.path.exists(subfolderPath):\n",
    "        os.makedirs(subfolderPath)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2107c362",
   "metadata": {},
   "source": [
    "### 4. Create the neuron group(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "4ac05e13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating Neuron Groups...\n"
     ]
    }
   ],
   "source": [
    "print('Creating Neuron Groups...')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "a7dda104",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO XXX: The events are running on the clockStep, I should at least fix them to use the (event_driven) setting in Brian2\n",
    "neuronsGrid = NeuronGroup(N_Neurons, Eqs_Neurons, threshold='v>vt',\n",
    "                            reset='''\n",
    "                            v = vr\n",
    "                            incoming_spikes_post = 0\n",
    "                            ''',\n",
    "                            refractory='0*ms',\n",
    "                            events={'P_ON': 'v > vt', 'P_OFF': '(timestep(t - lastspike, dt) > timestep(dt, dt) and v <= vt)'},\n",
    "                            method= Neuron_Params['method_Neuron'],\n",
    "                            namespace=Neuron_Params)\n",
    "\n",
    "\n",
    "# Define the created events, the actions to be taken as well as when they should be evaluated and executed\n",
    "neuronsGrid.set_event_schedule('P_ON', when = 'after_thresholds')\n",
    "neuronsGrid.run_on_event('P_ON', 'P = 1' , when = 'after_thresholds')\n",
    "neuronsGrid.set_event_schedule('P_OFF', when = 'groups')\n",
    "neuronsGrid.run_on_event('P_OFF', 'P = 0', when = 'groups')\n",
    "\n",
    "# FIXME: Verify the grid coordinates and assign the X and Y values to the neurons accordingly\n",
    "# Generate x and y values for each neuron\n",
    "# x_values = np.repeat(np.arange(grid_width), grid_height)\n",
    "# y_values = np.tile(np.arange(grid_height), grid_width)\n",
    "y_values, x_values = divmod(neuronsGrid.i, grid_width)\n",
    "neuronsGrid.X = x_values\n",
    "neuronsGrid.Y = y_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "7f1e7136",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Neuron Groups created successfully\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('Neuron Groups created successfully\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8891d013",
   "metadata": {},
   "source": [
    "#### 5. Create the synapses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "56c583e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating Synapse Connections...\n"
     ]
    }
   ],
   "source": [
    "print('Creating Synapse Connections...')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "29fdf2b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "Syn_Input_Neurons = Synapses(inputSpikesGen, neuronsGrid,\n",
    "                             'beta : 1 (constant)',\n",
    "                             on_pre='ExtIn_post = beta',\n",
    "                             method='exact',\n",
    "                             namespace=Syn_Params)\n",
    "\n",
    "# NOTE: In hopes of reducing simulation time, I am using _pre keyword to avoid the need for an autapse. Hence only one Synapse group is needed\n",
    "Syn_Neurons_Neurons = Synapses(neuronsGrid, neuronsGrid,\n",
    "                               '''\n",
    "                               W_Exc : 1\n",
    "                               W_Inh : 1\n",
    "                               ''',\n",
    "                               on_pre={\n",
    "                                   'pre':'incoming_spikes_post += 1; Exc_pre = W_Exc',\n",
    "                                   'pre_2': 'Inh_post += P_post * (W_Inh/incoming_spikes_post)'},\n",
    "                               method= 'exact',\n",
    "                               namespace=Syn_Params)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b604ddbd",
   "metadata": {},
   "source": [
    "### 6. Connect the synapses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "8598a6e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connect the first synapses from input to G_neurons on a 1 to 1 basis\n",
    "Syn_Input_Neurons.connect(j='i') \n",
    "Syn_Input_Neurons.beta = beta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "1579b974",
   "metadata": {},
   "outputs": [],
   "source": [
    "''' NOTE: The following code implements the connections for the Neurons to Neurons synapses\n",
    "which as mentioned before implicitly includes the autapses.\n",
    "The code below is a faster implementation of:\n",
    "    Syn_Neurons_Neurons.connect(condition='i != j and abs(X_pre - X_post) <= Num_Neighbours and abs(Y_pre - Y_post) <= Num_Neighbours')\n",
    "'''\n",
    "\n",
    "indexes_i, indexes_j = BrianHF.calculate_ChebyshevNeighbours(neuronsGrid, Num_Neighbours)\n",
    "Syn_Neurons_Neurons.connect(i=indexes_i, j=indexes_j)\n",
    "Syn_Neurons_Neurons.W_Exc = W_Exc\n",
    "Syn_Neurons_Neurons.W_Inh = W_Inh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "19df3cfa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Synapse Connections created successfully\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('Synapse Connections created successfully\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3286d5af",
   "metadata": {},
   "source": [
    "### 7. Set up monitors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "8a81bd76",
   "metadata": {},
   "outputs": [],
   "source": [
    "if GenerateInputVisuals:\n",
    "    SpikeMon_Input = SpikeMonitor(inputSpikesGen)    # Monitor the spikes from the input\n",
    "\n",
    "# IMPORTANT NOTE: The SpikeMonitor for the active neurons is moved to the simulation block to avoid memory issues.\n",
    "# The data is now broken down into smaller chunks and saved to disk\n",
    "\n",
    "# StateMon_Neurons = StateMonitor(neuronsGrid, variables=True, record=True)    # Monitor the state variables - True for all variables. NOTE: WARNING!! Excessive memory usage"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3acb171a",
   "metadata": {},
   "source": [
    "### 8. Run the simulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "093e24e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting simulation - Total time:  5. s\n",
      "\n",
      "Running simulation chunk 1/10 for 500.0 ms\n",
      "Running in a Jupyter notebook\n",
      "Starting simulation at t=0. s for a duration of 0.5 s\n",
      "0.5 s (100%) simulated in 4s\n",
      "\n",
      "Running simulation chunk 2/10 for 500.0 ms\n",
      "Running in a Jupyter notebook\n",
      "Starting simulation at t=0.5 s for a duration of 0.5 s\n",
      "260.5 ms (52%) simulated in 5s, estimated 5s remaining.\n",
      "0.4725 s (94%) simulated in 10s, estimated 1s remaining.\n",
      "0.5 s (100%) simulated in 10s\n",
      "\n",
      "Running simulation chunk 3/10 for 500.0 ms\n",
      "Running in a Jupyter notebook\n",
      "Starting simulation at t=1. s for a duration of 0.5 s\n",
      "152. ms (30%) simulated in 5s, estimated 11s remaining.\n",
      "310.5 ms (62%) simulated in 10s, estimated 6s remaining.\n",
      "0.465 s (93%) simulated in 15s, estimated 1s remaining.\n",
      "0.5 s (100%) simulated in 16s\n",
      "\n",
      "Running simulation chunk 4/10 for 500.0 ms\n",
      "Running in a Jupyter notebook\n",
      "Starting simulation at t=1.5 s for a duration of 0.5 s\n",
      "160.5 ms (32%) simulated in 5s, estimated 11s remaining.\n",
      "0.319 s (63%) simulated in 10s, estimated 6s remaining.\n",
      "0.4785 s (95%) simulated in 15s, estimated 1s remaining.\n",
      "0.5 s (100%) simulated in 16s\n",
      "\n",
      "Running simulation chunk 5/10 for 500.0 ms\n",
      "Running in a Jupyter notebook\n",
      "Starting simulation at t=2. s for a duration of 0.5 s\n",
      "141.5 ms (28%) simulated in 5s, estimated 13s remaining.\n",
      "290. ms (58%) simulated in 10s, estimated 7s remaining.\n",
      "0.4415 s (88%) simulated in 15s, estimated 2s remaining.\n",
      "0.5 s (100%) simulated in 16s\n",
      "\n",
      "Running simulation chunk 6/10 for 500.0 ms\n",
      "Running in a Jupyter notebook\n",
      "Starting simulation at t=2.5 s for a duration of 0.5 s\n",
      "154.5 ms (30%) simulated in 5s, estimated 11s remaining.\n",
      "296. ms (59%) simulated in 10s, estimated 7s remaining.\n",
      "0.439 s (87%) simulated in 15s, estimated 2s remaining.\n",
      "0.5 s (100%) simulated in 17s\n",
      "\n",
      "Running simulation chunk 7/10 for 500.0 ms\n",
      "Running in a Jupyter notebook\n",
      "Starting simulation at t=3. s for a duration of 0.5 s\n",
      "142. ms (28%) simulated in 5s, estimated 13s remaining.\n",
      "286. ms (57%) simulated in 10s, estimated 8s remaining.\n",
      "0.4145 s (82%) simulated in 15s, estimated 3s remaining.\n",
      "0.5 s (100%) simulated in 18s\n",
      "\n",
      "Running simulation chunk 8/10 for 500.0 ms\n",
      "Running in a Jupyter notebook\n",
      "Starting simulation at t=3.5 s for a duration of 0.5 s\n",
      "145.5 ms (29%) simulated in 5s, estimated 12s remaining.\n",
      "291.5 ms (58%) simulated in 10s, estimated 7s remaining.\n",
      "0.4425 s (88%) simulated in 15s, estimated 2s remaining.\n",
      "0.5 s (100%) simulated in 17s\n",
      "\n",
      "Running simulation chunk 9/10 for 500.0 ms\n",
      "Running in a Jupyter notebook\n",
      "Starting simulation at t=4. s for a duration of 0.5 s\n",
      "147.5 ms (29%) simulated in 5s, estimated 12s remaining.\n",
      "291. ms (58%) simulated in 10s, estimated 7s remaining.\n",
      "0.427 s (85%) simulated in 15s, estimated 3s remaining.\n",
      "0.5 s (100%) simulated in 17s\n",
      "\n",
      "Running simulation chunk 10/10 for 500.0 ms\n",
      "Running in a Jupyter notebook\n",
      "Starting simulation at t=4.5 s for a duration of 0.5 s\n",
      "139. ms (27%) simulated in 5s, estimated 13s remaining.\n",
      "278. ms (55%) simulated in 10s, estimated 8s remaining.\n",
      "0.3985 s (79%) simulated in 15s, estimated 4s remaining.\n",
      "0.5 s (100%) simulated in 18s\n",
      "Simulation complete  \n",
      "\n"
     ]
    }
   ],
   "source": [
    "BrianLogger.log_level_error()    # Only log errors to avoid excessive output\n",
    "\n",
    "warn = ''\n",
    "N = 10  # Number of runs\n",
    "simTime = 5e3  # Total simulation time\n",
    "run_time = simTime / N  # Duration of each run\n",
    "spikeTimeStamps = np.array([])\n",
    "spikeIndices = np.array([], dtype=int)\n",
    "\n",
    "# SpikeMon_Neurons = SpikeMonitor(neuronsGrid)    # Monitor the spikes from the neuron grid\n",
    "\n",
    "\n",
    "print(\"Starting simulation - Total time: \", simTime*ms)\n",
    "for i in range(N):\n",
    "    print(f\"\\nRunning simulation chunk {i+1}/{N} for {run_time} ms\")\n",
    "    SpikeMon_Neurons = SpikeMonitor(neuronsGrid)    # Monitor the spikes from the neuron grid\n",
    "    \n",
    "    if 'ipykernel' in sys.modules:\n",
    "        # Running in a Jupyter notebook\n",
    "        print(\"Running in a Jupyter notebook\")\n",
    "        reportVar = 'text'\n",
    "        report_periodVar = 5*second\n",
    "    else:\n",
    "        # Not running in a Jupyter notebook\n",
    "        print(\"Not running in a Jupyter notebook\")\n",
    "        reportVar = BrianHF.ProgressBar()\n",
    "        report_periodVar = 2*second\n",
    "    \n",
    "    FailedSim = False\n",
    "    \n",
    "    run(run_time*ms, report=reportVar, report_period=report_periodVar, profile=False)\n",
    "\n",
    "        \n",
    "    # try:\n",
    "    #     run(run_time*ms, report=reportVar, report_period=report_periodVar, profile=False)\n",
    "    #     # print(profiling_summary())\n",
    "    # except Exception as e:\n",
    "    #     print(\"Simulation failed:\", str(e), '\\n')\n",
    "    #     print(\"Trying to re-run by dividing the time into smaller chunks\\n\")\n",
    "    #     N_inner = 5\n",
    "    #     run_time_inner = run_time / N_inner\n",
    "    #     for j in range(N_inner):\n",
    "    #         print(f\"Running INNER simulation chunk {j+1}/{N_inner} for {run_time_inner} ms\")\n",
    "    #         try:\n",
    "    #             run(run_time_inner*ms, report=reportVar, report_period=report_periodVar, profile=False)\n",
    "    #         except Exception as e_inner:\n",
    "    #             print(\"Simulation failed:\", str(e_inner))\n",
    "    #             warn = \" - WARNING: The results may be incomplete\"\n",
    "    #             FailedSim = True\n",
    "    #             break\n",
    "    #     if not FailedSim:\n",
    "    #         break\n",
    "        \n",
    "        \n",
    "    if SpikeMon_Neurons.num_spikes > 0:\n",
    "        spikeTimeStamps = np.append(spikeTimeStamps, SpikeMon_Neurons.t[:])\n",
    "        spikeIndices = np.append(spikeIndices, SpikeMon_Neurons.i[:])\n",
    "    \n",
    "    del SpikeMon_Neurons\n",
    "    gc.collect()\n",
    "    \n",
    "print(\"Simulation complete\",warn,\"\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48b33a71",
   "metadata": {},
   "source": [
    "#### _9. (Optional) Visualize the results_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "4f98967b",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "# print(\"Generating Visualizable Outputs:\")\n",
    "# BrianHF.visualise_connectivity(Syn_Input_Neurons)\n",
    "# BrianHF.visualise_spikes([SpikeMon_Input, SpikeMon_Neurons])\n",
    "# BrianHF.visualise_spike_difference(SpikeMon_Input, SpikeMon_Neurons)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "2d4171bd",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "# Generate the frames for input\n",
    "if GenerateInputVisuals:\n",
    "    print(\"Generating Frames for Input...\", end=' ')\n",
    "    inputFrames = BrianHF.generate_frames(SpikeMon_Input.t, SpikeMon_Input.i, grid_width, grid_height, num_neurons=N_Neurons)\n",
    "    print(\"Input Frames Generation Complete.\")\n",
    "\n",
    "    # Save the frames\n",
    "    if SaveNumpyFrames:\n",
    "        print(\"Saving Input Frames as Numpy Arrays...\")\n",
    "        filename = os.path.join(resultPath, 'numpyFrames', inputStr+'.npy')\n",
    "        if os.path.exists(filename):\n",
    "            filename = os.path.join(resultPath, 'numpyFrames', f\"{inputStr}_{int(time.time())}.npy\")\n",
    "        np.save(filename, inputFrames)\n",
    "        print(\"Input Numpy Array Saved.\")\n",
    "\n",
    "\n",
    "    # Generate the GIFs from the frames\n",
    "    if GenerateGIFs:\n",
    "        print(\"Generating Input GIFs...\")\n",
    "        filename = os.path.join(resultPath, 'gifs', inputStr+'.gif')\n",
    "        if os.path.exists(filename):\n",
    "            filename = os.path.join(resultPath, 'gifs', f\"{inputStr}_{int(time.time())}.gif\")\n",
    "        BrianHF.generate_gif(inputFrames, filename, simTime, replicateDuration=True, duration=1e-8)\n",
    "        print(\"Input GIF Generation Complete.\")\n",
    "\n",
    "\n",
    "    # Generate the Videos from the frames\n",
    "    if GenerateVideos:\n",
    "        print(\"Generating Videos...\")\n",
    "        filename = os.path.join(resultPath, 'videos', inputStr+'.mp4')\n",
    "        if os.path.exists(filename):\n",
    "            filename = os.path.join(resultPath, 'videos', f\"{inputStr}_{int(time.time())}.mp4\")\n",
    "        BrianHF.generate_video(inputFrames, filename, simTime/1000)\n",
    "        print(\"Input Video Generation Complete.\")\n",
    "\n",
    "    del inputFrames\n",
    "    del SpikeMon_Input\n",
    "    gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "9a4268e5",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exporting Yarp Spike Log...\n",
      "Converting event arrays to bottle-ready string format ...\n",
      "Breaking into bottles by time\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 295241689/295241689 [09:32<00:00, 515400.51it/s]\n"
     ]
    }
   ],
   "source": [
    "print(\"Exporting Yarp Spike Log...\")\n",
    "filename = os.path.join(resultPath, inputPath, logPath, 'data.log')\n",
    "if os.path.exists(filename):\n",
    "    filename = os.path.join(resultPath, inputPath, logPath, f\"data_{int(time.time())}.log\")\n",
    "BrianHF.generate_YarpDvs(spikeTimeStamps, spikeIndices, neuronsGrid, filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "419f1ae4",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "if GenerateOutputVisuals:\n",
    "    \n",
    "    print(\"Generating Frames for Output...\", end=' ')\n",
    "    #outputFrames = BrianHF.generate_frames(SpikeMon_Neurons.t/ms, SpikeMon_Neurons.i, grid_width, grid_height, num_neurons=N_Neurons)\n",
    "    outputFrames = BrianHF.generate_frames(spikeTimeStamps, spikeIndices, grid_width, grid_height, num_neurons=N_Neurons)\n",
    "    print(\"Output Frames Generation Complete.\")\n",
    "    videoTime = spikeTimeStamps[-1] if len(spikeTimeStamps) > 0 else simTime\n",
    "    print(f\"Video Time: {videoTime}\")\n",
    "    \n",
    "    del spikeTimeStamps, spikeIndices\n",
    "    gc.collect()\n",
    "    \n",
    "    \n",
    "    # Save the frames\n",
    "    if SaveNumpyFrames:\n",
    "        print(\"Saving Input Frames as Numpy Arrays...\")\n",
    "        filename = os.path.join(resultPath, 'numpyFrames', outputStr+'.npy')\n",
    "        if os.path.exists(filename):\n",
    "            filename = os.path.join(resultPath, 'numpyFrames', f\"{outputStr}_{int(time.time())}.npy\")\n",
    "        np.save(filename, outputFrames)\n",
    "        print(\"Output Numpy Array Saved.\")\n",
    "\n",
    "\n",
    "    # Generate the GIFs from the frames\n",
    "    if GenerateGIFs:\n",
    "        print(\"Generating Input GIFs...\")\n",
    "        filename = os.path.join(resultPath, 'gifs', outputStr+'.gif')\n",
    "        if os.path.exists(filename):\n",
    "            filename = os.path.join(resultPath, 'gifs', f\"{outputStr}_{int(time.time())}.gif\")\n",
    "        BrianHF.generate_gif(outputFrames, filename, simTime, replicateDuration=True, duration=1e-8)\n",
    "        print(\"Output GIF Generation Complete.\")\n",
    "\n",
    "\n",
    "    # Generate the Videos from the frames\n",
    "    if GenerateVideos:\n",
    "        print(\"Generating Videos...\")\n",
    "        filename = os.path.join(resultPath, 'videos', outputStr+'.mp4')\n",
    "        if os.path.exists(filename):\n",
    "            filename = os.path.join(resultPath, 'videos', f\"{outputStr}_{int(time.time())}.mp4\")\n",
    "        BrianHF.generate_video(outputFrames, filename, videoTime)\n",
    "        print(\"Output Video Generation Complete.\")\n",
    "\n",
    "    del outputFrames"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "formats": "ipynb,py"
  },
  "kernelspec": {
   "display_name": "IIT",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
