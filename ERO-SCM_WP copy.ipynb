{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6d126ffc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from brian2 import *\n",
    "# set_device('cpp_standalone') # for faster execution - builds a standalone C++ program\n",
    "\n",
    "import NeuronEquations\n",
    "import BrianHF\n",
    "import numpy as np\n",
    "\n",
    "from bimvee.importAe import importAe\n",
    "from EvCamDatabase import *\n",
    "\n",
    "import os\n",
    "import gc\n",
    "import time\n",
    "\n",
    "# TODO XXX: Turn all lists into numpy arrays for the sake of memory efficiency"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c1c0cc6",
   "metadata": {},
   "source": [
    "### 0. Importing the data using bimvee"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f3dc1209",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'filePathOrName': 'InputData/h36m_sample/cam2_S1_Directions/ch0dvs'}\n",
      "{'filePathOrName': 'InputData/h36m_sample/cam2_S1_Directions/ch0dvs'}\n",
      "importIitYarp trying path: InputData/h36m_sample/cam2_S1_Directions/ch0dvs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 32375/32375 [00:05<00:00, 6082.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Examining info.log: InputData/h36m_sample/cam2_S1_Directions/ch0dvs/info.log\n"
     ]
    }
   ],
   "source": [
    "# XXX: Extract the event stream using bimvee - needs refactoring to be more general\n",
    "grid_width, grid_height= IDNW['width'], IDNW['height']\n",
    "inputPath = 'h36m_sample/cam2_S1_Directions/ch0dvs'\n",
    "events = importAe(filePathOrName=os.path.join('InputData',inputPath))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "11440073",
   "metadata": {},
   "outputs": [],
   "source": [
    "eventStream = next(BrianHF.find_keys(events, 'dvs'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1aea5bd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# grid_width, grid_height= DAVIS_346B['width'], DAVIS_346B['height']\n",
    "# inputPath = 'MVSEC_short_outdoor'\n",
    "# events = importAe(filePathOrName=os.path.join('InputData',inputPath))\n",
    "# try:\n",
    "#     eventStream = events[0]['data']['left']['dvs']\n",
    "# except:\n",
    "#     eventStream = events[0]['data']['right']['dvs']\n",
    "# eventStream.popitem()\n",
    "# print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93bd1f3c",
   "metadata": {},
   "source": [
    "## Steps for the setting up the network:\n",
    "1. Generate the input spikes\n",
    "2. Set the parameters for the Simulation and Network (Neurons, Synapses, etc.)\n",
    "3. Prepare the directory structure for saving the results\n",
    "4. Create the neuron group(s)\n",
    "5. Create the synapses\n",
    "6. Connect the synapses\n",
    "7. Define the weights of the synapses\n",
    "8. Set up monitors according to need\n",
    "9. Run the simulation\n",
    "10. (Optional) Visualize the results\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dfa559a",
   "metadata": {},
   "source": [
    "### 1. Generate the input spikes from the event stream\n",
    "###### Brian Simulation Scope"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "553dd49b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting the event data...\n",
      "Polarity is ignored. All events are extracted.\n",
      "Selecting a percentage of the spikes at regular intervals... Percentage:  100.0 %\n",
      "The maximum x index 639 while the width is 640\n",
      "The maximum y index 479 while the height is 480\n",
      "The x, y, and timestamp indices are equal, the data is correct.\n",
      "Checking for duplicate pairs...\n",
      "Duplicate pairs found. Total Number of duplicates: 822\n",
      "Total number of pairs/spikes after removing duplicates: 5434099 pairs.\n",
      "The maximum timestamp (scaled) 32266.998 ms.\n",
      "The recommended simulation time (scaled) is 32267.0 ms.\n",
      "The minimum time step (scaled) is 0.499999999996362 ms.\n",
      "The recommended clock time step (scaled) is 0.5 ms.\n",
      "Input event stream successfully converted to spike trains\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# HACK XXX: The input is now not in real time, must be fixed eventually to process real time event data\n",
    "# IMPORTANT NOTE: Output is float, so we need to convert to Quantities (i.e give them units)\n",
    "\n",
    "# Simulation Parameters\n",
    "defaultclock.dt = 0.5*ms\n",
    "samplePerc = 1.0\n",
    "SaveNumpyFrames = False\n",
    "GenerateGIFs = False\n",
    "GenerateVideos = True\n",
    "\n",
    "GenerateInputVisuals = False\n",
    "GenerateOutputVisuals = False\n",
    "\n",
    "simTime, clockStep, inputSpikesGen = BrianHF.event_to_spike(eventStream, grid_width, grid_height,\n",
    "                                                            dt = defaultclock.dt, timeScale = 1.0, samplePercentage=samplePerc, interSpikeTiming=None)\n",
    "# defaultclock.dt = clockStep*ms\n",
    "print(\"Input event stream successfully converted to spike trains\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2657cbf5",
   "metadata": {},
   "source": [
    "### 2. Set the parameters for the Simulation and Network (Neurons, Synapses, etc.)\n",
    "Parameter values can be tuned per namespace (this is done for clarity purposes)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9376017c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOTE: The values are unitless for now, time constants are in ms simply to be able to tune to the simulation clock\n",
    "\n",
    "# Neuron Parameters\n",
    "N_Neurons = grid_width * grid_height    # Number of neurons\n",
    "\n",
    "Neuron_Params = {'tau': 0.2*ms, 'vt': 0.1, 'vr': 0.0, 'P': 0, 'incoming_spikes': 0, 'method_Neuron': 'exact'}\n",
    "tau = Neuron_Params['tau']\n",
    "vt = Neuron_Params['vt']\n",
    "vr = Neuron_Params['vr']\n",
    "P = Neuron_Params['P']\n",
    "incoming_spikes = Neuron_Params['incoming_spikes']\n",
    "\n",
    "Eqs_Neurons = NeuronEquations.EQ_SCM_IF    # Neurons Equation\n",
    " \n",
    "# Synapse Parameters\n",
    "'''\n",
    "Neighborhood Size (num_Neighbors) - Affects the number of neighbors a central neuron based on the L1 Distance\n",
    "Neighboring Neurons --> (abs(X_pre - X_post) <= Num_Neighbours  and abs(Y_pre - Y_post) <= Num_Neighbours)\n",
    "'''\n",
    "Syn_Params = {'Num_Neighbours' : 8, 'beta': 0.5, 'W_Exc': 6.0, 'W_Inh': -0.01, 'method_Syn': 'exact'}\n",
    "Num_Neighbours = Syn_Params['Num_Neighbours']\n",
    "beta = Syn_Params['beta']\n",
    "W_Exc = Syn_Params['W_Exc']\n",
    "W_Inh = Syn_Params['W_Inh']\n",
    "\n",
    "# Generate the dictionary of parameters for the network\n",
    "networkParams = {**Neuron_Params, **Syn_Params, 'Sim_Clock': defaultclock.dt, 'Sample_Perc': samplePerc}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bf75640",
   "metadata": {},
   "source": [
    "### 3. Prepare the directory structure for saving the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3f49d544",
   "metadata": {},
   "outputs": [],
   "source": [
    "resultPath = 'SimulationResults'\n",
    "inputStr = BrianHF.filePathGenerator('SCM_LIF_IN', networkParams).replace(\" \", \"\")\n",
    "outputStr = BrianHF.filePathGenerator('SCM_LIF_OUT', networkParams).replace(\" \", \"\")\n",
    "\n",
    "# Create the folder if it doesn't exist\n",
    "if not os.path.exists(resultPath):\n",
    "    os.makedirs(resultPath)\n",
    "\n",
    "logPath = os.path.join('YarpSpikeLog', outputStr)\n",
    "# Create the subfolders if they don't exist\n",
    "subfolders = ['spikeFrames', 'numpyFrames', 'gifs', 'videos', logPath]\n",
    "for subfolder in subfolders:\n",
    "    subfolderPath = os.path.join(resultPath, inputPath, subfolder)\n",
    "    if not os.path.exists(subfolderPath):\n",
    "        os.makedirs(subfolderPath)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2107c362",
   "metadata": {},
   "source": [
    "### 4. Create the neuron group(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4ac05e13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating Neuron Groups...\n"
     ]
    }
   ],
   "source": [
    "print('Creating Neuron Groups...')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a7dda104",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO XXX: The events are running on the clockStep, I should at least fix them to use the (event_driven) setting in Brian2\n",
    "neuronsGrid = NeuronGroup(N_Neurons, Eqs_Neurons, threshold='v>vt',\n",
    "                            reset='''\n",
    "                            v = vr\n",
    "                            incoming_spikes_post = 0\n",
    "                            ''',\n",
    "                            refractory='0*ms',\n",
    "                            events={'P_ON': 'v > vt', 'P_OFF': '(timestep(t - lastspike, dt) > timestep(dt, dt) and v <= vt)'},\n",
    "                            method= Neuron_Params['method_Neuron'],\n",
    "                            namespace=Neuron_Params)\n",
    "\n",
    "\n",
    "# Define the created events, the actions to be taken as well as when they should be evaluated and executed\n",
    "neuronsGrid.set_event_schedule('P_ON', when = 'after_thresholds')\n",
    "neuronsGrid.run_on_event('P_ON', 'P = 1' , when = 'after_thresholds')\n",
    "neuronsGrid.set_event_schedule('P_OFF', when = 'groups')\n",
    "neuronsGrid.run_on_event('P_OFF', 'P = 0', when = 'groups')\n",
    "\n",
    "# FIXME: Verify the grid coordinates and assign the X and Y values to the neurons accordingly\n",
    "# Generate x and y values for each neuron\n",
    "# x_values = np.repeat(np.arange(grid_width), grid_height)\n",
    "# y_values = np.tile(np.arange(grid_height), grid_width)\n",
    "y_values, x_values = divmod(neuronsGrid.i, grid_width)\n",
    "neuronsGrid.X = x_values\n",
    "neuronsGrid.Y = y_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7f1e7136",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Neuron Groups created successfully\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('Neuron Groups created successfully\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8891d013",
   "metadata": {},
   "source": [
    "#### 5. Create the synapses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "56c583e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating Synapse Connections...\n"
     ]
    }
   ],
   "source": [
    "print('Creating Synapse Connections...')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "29fdf2b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "Syn_Input_Neurons = Synapses(inputSpikesGen, neuronsGrid,\n",
    "                             'beta : 1 (constant)',\n",
    "                             on_pre='ExtIn_post = beta',\n",
    "                             method='exact',\n",
    "                             namespace=Syn_Params)\n",
    "\n",
    "# NOTE: In hopes of reducing simulation time, I am using _pre keyword to avoid the need for an autapse. Hence only one Synapse group is needed\n",
    "Syn_Neurons_Neurons = Synapses(neuronsGrid, neuronsGrid,\n",
    "                               '''\n",
    "                               W_Exc : 1\n",
    "                               W_Inh : 1\n",
    "                               ''',\n",
    "                               on_pre={\n",
    "                                   'pre':'incoming_spikes_post += 1; Exc_pre = W_Exc',\n",
    "                                   'pre_2': 'Inh_post += P_post * W_Inh'},\n",
    "                               method= 'exact',\n",
    "                               namespace=Syn_Params)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b604ddbd",
   "metadata": {},
   "source": [
    "### 6. Connect the synapses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8598a6e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connect the first synapses from input to G_neurons on a 1 to 1 basis\n",
    "Syn_Input_Neurons.connect(j='i') \n",
    "Syn_Input_Neurons.beta = beta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1579b974",
   "metadata": {},
   "outputs": [],
   "source": [
    "''' NOTE: The following code implements the connections for the Neurons to Neurons synapses\n",
    "which as mentioned before implicitly includes the autapses.\n",
    "The code below is a faster implementation of:\n",
    "    Syn_Neurons_Neurons.connect(condition='i != j and abs(X_pre - X_post) <= Num_Neighbours and abs(Y_pre - Y_post) <= Num_Neighbours')\n",
    "'''\n",
    "\n",
    "indexes_i, indexes_j = BrianHF.calculate_ChebyshevNeighbours(neuronsGrid, Num_Neighbours)\n",
    "Syn_Neurons_Neurons.connect(i=indexes_i, j=indexes_j)\n",
    "Syn_Neurons_Neurons.W_Exc = W_Exc\n",
    "Syn_Neurons_Neurons.W_Inh = W_Inh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "19df3cfa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Synapse Connections created successfully\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('Synapse Connections created successfully\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3286d5af",
   "metadata": {},
   "source": [
    "### 7. Set up monitors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8a81bd76",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "if GenerateInputVisuals:\n",
    "    SpikeMon_Input = SpikeMonitor(inputSpikesGen)    # Monitor the spikes from the input\n",
    "\n",
    "# IMPORTANT NOTE: The SpikeMonitor for the active neurons is moved to the simulation block to avoid memory issues.\n",
    "# The data is now broken down into smaller chunks and saved to disk\n",
    "\n",
    "# StateMon_Neurons = StateMonitor(neuronsGrid, variables=True, record=True)    # Monitor the state variables - True for all variables. NOTE: WARNING!! Excessive memory usage"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3acb171a",
   "metadata": {},
   "source": [
    "### 8. Run the simulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "093e24e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting simulation - Total time:  32.267 s\n",
      "\n",
      "Running simulation chunk 1/10 for 3226.7 ms\n",
      "Running in a Jupyter notebook\n",
      "Starting simulation at t=0. s for a duration of 3.2267 s\n",
      "0.8455 s (26%) simulated in 5s, estimated 14s remaining.\n",
      "1.509 s (46%) simulated in 10s, estimated 11s remaining.\n",
      "2.24 s (69%) simulated in 15s, estimated 7s remaining.\n",
      "2.943 s (91%) simulated in 20s, estimated 2s remaining.\n",
      "3.2267 s (100%) simulated in 22s\n",
      "\n",
      "Running simulation chunk 2/10 for 3226.7 ms\n",
      "Running in a Jupyter notebook\n",
      "Starting simulation at t=3.2267 s for a duration of 3.2267 s\n",
      "0.5288 s (16%) simulated in 5s, estimated 26s remaining.\n",
      "1.0488 s (32%) simulated in 10s, estimated 21s remaining.\n",
      "1.5558 s (48%) simulated in 15s, estimated 16s remaining.\n",
      "1.9778 s (61%) simulated in 20s, estimated 13s remaining.\n",
      "2.4258 s (75%) simulated in 25s, estimated 8s remaining.\n",
      "2.8913 s (89%) simulated in 30s, estimated 3s remaining.\n",
      "3.2267 s (100%) simulated in 33s\n",
      "\n",
      "Running simulation chunk 3/10 for 3226.7 ms\n",
      "Running in a Jupyter notebook\n",
      "Starting simulation at t=6.4534 s for a duration of 3.2267 s\n",
      "0.4816 s (14%) simulated in 5s, estimated 29s remaining.\n",
      "0.9521 s (29%) simulated in 10s, estimated 24s remaining.\n",
      "1.4086 s (43%) simulated in 15s, estimated 19s remaining.\n",
      "1.8476 s (57%) simulated in 20s, estimated 15s remaining.\n",
      "2.2971 s (71%) simulated in 25s, estimated 10s remaining.\n",
      "2.7481 s (85%) simulated in 30s, estimated 5s remaining.\n",
      "3.1866 s (98%) simulated in 35s, estimated < 1s remaining.\n",
      "3.2267 s (100%) simulated in 35s\n",
      "\n",
      "Running simulation chunk 4/10 for 3226.7 ms\n",
      "Running in a Jupyter notebook\n",
      "Starting simulation at t=9.6801 s for a duration of 3.2267 s\n",
      "0.4399 s (13%) simulated in 5s, estimated 32s remaining.\n",
      "0.8764 s (27%) simulated in 10s, estimated 27s remaining.\n",
      "1.3059 s (40%) simulated in 15s, estimated 22s remaining.\n",
      "1.7419 s (53%) simulated in 20s, estimated 17s remaining.\n",
      "2.1659 s (67%) simulated in 25s, estimated 12s remaining.\n",
      "2.5999 s (80%) simulated in 30s, estimated 7s remaining.\n",
      "3.0304 s (93%) simulated in 35s, estimated 2s remaining.\n",
      "3.2267 s (100%) simulated in 37s\n",
      "\n",
      "Running simulation chunk 5/10 for 3226.7 ms\n",
      "Running in a Jupyter notebook\n",
      "Starting simulation at t=12.9068 s for a duration of 3.2267 s\n",
      "0.3882 s (12%) simulated in 5s, estimated 37s remaining.\n",
      "0.7722 s (23%) simulated in 10s, estimated 32s remaining.\n",
      "1.1237 s (34%) simulated in 15s, estimated 28s remaining.\n",
      "1.4792 s (45%) simulated in 20s, estimated 24s remaining.\n",
      "1.8432 s (57%) simulated in 25s, estimated 19s remaining.\n",
      "2.2282 s (69%) simulated in 30s, estimated 13s remaining.\n",
      "2.6177 s (81%) simulated in 35s, estimated 8s remaining.\n",
      "2.9942 s (92%) simulated in 40s, estimated 3s remaining.\n",
      "3.2267 s (100%) simulated in 43s\n",
      "\n",
      "Running simulation chunk 6/10 for 3226.7 ms\n",
      "Running in a Jupyter notebook\n",
      "Starting simulation at t=16.1335 s for a duration of 3.2267 s\n",
      "0.374 s (11%) simulated in 5s, estimated 38s remaining.\n",
      "0.754 s (23%) simulated in 10s, estimated 33s remaining.\n",
      "1.1395 s (35%) simulated in 15s, estimated 27s remaining.\n",
      "1.5125 s (46%) simulated in 20s, estimated 23s remaining.\n",
      "1.8915 s (58%) simulated in 25s, estimated 18s remaining.\n",
      "2.27 s (70%) simulated in 30s, estimated 13s remaining.\n",
      "2.6475 s (82%) simulated in 35s, estimated 8s remaining.\n",
      "3.005 s (93%) simulated in 40s, estimated 3s remaining.\n",
      "3.2267 s (100%) simulated in 43s\n",
      "\n",
      "Running simulation chunk 7/10 for 3226.7 ms\n",
      "Running in a Jupyter notebook\n",
      "Starting simulation at t=19.3602 s for a duration of 3.2267 s\n",
      "0.3633 s (11%) simulated in 5s, estimated 39s remaining.\n",
      "0.7093 s (21%) simulated in 10s, estimated 36s remaining.\n",
      "1.0498 s (32%) simulated in 15s, estimated 31s remaining.\n",
      "1.4173 s (43%) simulated in 20s, estimated 26s remaining.\n",
      "1.7833 s (55%) simulated in 25s, estimated 20s remaining.\n",
      "2.1253 s (65%) simulated in 30s, estimated 16s remaining.\n",
      "2.4848 s (77%) simulated in 35s, estimated 10s remaining.\n",
      "2.8458 s (88%) simulated in 40s, estimated 5s remaining.\n",
      "3.2053 s (99%) simulated in 45s, estimated < 1s remaining.\n",
      "3.2267 s (100%) simulated in 45s\n",
      "\n",
      "Running simulation chunk 8/10 for 3226.7 ms\n",
      "Running in a Jupyter notebook\n",
      "Starting simulation at t=22.5869 s for a duration of 3.2267 s\n",
      "0.3386 s (10%) simulated in 5s, estimated 43s remaining.\n",
      "0.6866 s (21%) simulated in 10s, estimated 37s remaining.\n",
      "1.0331 s (32%) simulated in 15s, estimated 32s remaining.\n",
      "1.3801 s (42%) simulated in 20s, estimated 27s remaining.\n",
      "1.7291 s (53%) simulated in 25s, estimated 22s remaining.\n",
      "2.0616 s (63%) simulated in 30s, estimated 17s remaining.\n",
      "2.4086 s (74%) simulated in 35s, estimated 12s remaining.\n",
      "2.7601 s (85%) simulated in 40s, estimated 7s remaining.\n",
      "3.1081 s (96%) simulated in 45s, estimated 2s remaining.\n",
      "3.2267 s (100%) simulated in 46s\n"
     ]
    }
   ],
   "source": [
    "BrianLogger.log_level_error()    # Only log errors to avoid excessive output\n",
    "\n",
    "warn = ''\n",
    "N = 10  # Number of runs\n",
    "run_time = simTime / N  # Duration of each run\n",
    "spikeTimeStamps = np.array([])\n",
    "spikeIndices = np.array([], dtype=int)\n",
    "\n",
    "# SpikeMon_Neurons = SpikeMonitor(neuronsGrid)    # Monitor the spikes from the neuron grid\n",
    "\n",
    "\n",
    "print(\"Starting simulation - Total time: \", simTime*ms)\n",
    "for i in range(N):\n",
    "    print(f\"\\nRunning simulation chunk {i+1}/{N} for {run_time} ms\")\n",
    "    SpikeMon_Neurons = SpikeMonitor(neuronsGrid)    # Monitor the spikes from the neuron grid\n",
    "    \n",
    "    if 'ipykernel' in sys.modules:\n",
    "        # Running in a Jupyter notebook\n",
    "        print(\"Running in a Jupyter notebook\")\n",
    "        reportVar = 'text'\n",
    "        report_periodVar = 5*second\n",
    "    else:\n",
    "        # Not running in a Jupyter notebook\n",
    "        print(\"Not running in a Jupyter notebook\")\n",
    "        reportVar = BrianHF.ProgressBar()\n",
    "        report_periodVar = 2*second\n",
    "    \n",
    "    FailedSim = False\n",
    "    \n",
    "    run(run_time*ms, report=reportVar, report_period=report_periodVar, profile=False)\n",
    "\n",
    "        \n",
    "    # try:\n",
    "    #     run(run_time*ms, report=reportVar, report_period=report_periodVar, profile=False)\n",
    "    #     # print(profiling_summary())\n",
    "    # except Exception as e:\n",
    "    #     print(\"Simulation failed:\", str(e), '\\n')\n",
    "    #     print(\"Trying to re-run by dividing the time into smaller chunks\\n\")\n",
    "    #     N_inner = 5\n",
    "    #     run_time_inner = run_time / N_inner\n",
    "    #     for j in range(N_inner):\n",
    "    #         print(f\"Running INNER simulation chunk {j+1}/{N_inner} for {run_time_inner} ms\")\n",
    "    #         try:\n",
    "    #             run(run_time_inner*ms, report=reportVar, report_period=report_periodVar, profile=False)\n",
    "    #         except Exception as e_inner:\n",
    "    #             print(\"Simulation failed:\", str(e_inner))\n",
    "    #             warn = \" - WARNING: The results may be incomplete\"\n",
    "    #             FailedSim = True\n",
    "    #             break\n",
    "    #     if not FailedSim:\n",
    "    #         break\n",
    "        \n",
    "        \n",
    "    if SpikeMon_Neurons.num_spikes > 0:\n",
    "        spikeTimeStamps = np.append(spikeTimeStamps, SpikeMon_Neurons.t[:])\n",
    "        spikeIndices = np.append(spikeIndices, SpikeMon_Neurons.i[:])\n",
    "    \n",
    "    del SpikeMon_Neurons\n",
    "    gc.collect()\n",
    "    \n",
    "print(\"Simulation complete\",warn,\"\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48b33a71",
   "metadata": {},
   "source": [
    "#### _9. (Optional) Visualize the results_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f98967b",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "# print(\"Generating Visualizable Outputs:\")\n",
    "# BrianHF.visualise_connectivity(Syn_Input_Neurons)\n",
    "# BrianHF.visualise_spikes([SpikeMon_Input, SpikeMon_Neurons])\n",
    "# BrianHF.visualise_spike_difference(SpikeMon_Input, SpikeMon_Neurons)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d4171bd",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "# Generate the frames for input\n",
    "if GenerateInputVisuals:\n",
    "    print(\"Generating Frames for Input...\", end=' ')\n",
    "    inputFrames = BrianHF.generate_frames(SpikeMon_Input.t, SpikeMon_Input.i, grid_width, grid_height, num_neurons=N_Neurons)\n",
    "    print(\"Input Frames Generation Complete.\")\n",
    "\n",
    "    # Save the frames\n",
    "    if SaveNumpyFrames:\n",
    "        print(\"Saving Input Frames as Numpy Arrays...\")\n",
    "        filename = os.path.join(resultPath, 'numpyFrames', inputStr+'.npy')\n",
    "        if os.path.exists(filename):\n",
    "            filename = os.path.join(resultPath, 'numpyFrames', f\"{inputStr}_{int(time.time())}.npy\")\n",
    "        np.save(filename, inputFrames)\n",
    "        print(\"Input Numpy Array Saved.\")\n",
    "\n",
    "\n",
    "    # Generate the GIFs from the frames\n",
    "    if GenerateGIFs:\n",
    "        print(\"Generating Input GIFs...\")\n",
    "        filename = os.path.join(resultPath, 'gifs', inputStr+'.gif')\n",
    "        if os.path.exists(filename):\n",
    "            filename = os.path.join(resultPath, 'gifs', f\"{inputStr}_{int(time.time())}.gif\")\n",
    "        BrianHF.generate_gif(inputFrames, filename, simTime, replicateDuration=True, duration=1e-8)\n",
    "        print(\"Input GIF Generation Complete.\")\n",
    "\n",
    "\n",
    "    # Generate the Videos from the frames\n",
    "    if GenerateVideos:\n",
    "        print(\"Generating Videos...\")\n",
    "        filename = os.path.join(resultPath, 'videos', inputStr+'.mp4')\n",
    "        if os.path.exists(filename):\n",
    "            filename = os.path.join(resultPath, 'videos', f\"{inputStr}_{int(time.time())}.mp4\")\n",
    "        BrianHF.generate_video(inputFrames, filename, simTime/1000)\n",
    "        print(\"Input Video Generation Complete.\")\n",
    "\n",
    "    del inputFrames\n",
    "    del SpikeMon_Input\n",
    "    gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a4268e5",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "print(\"Exporting Yarp Spike Log...\")\n",
    "filename = os.path.join(resultPath, inputPath, logPath, 'data.log')\n",
    "if os.path.exists(filename):\n",
    "    filename = os.path.join(resultPath, inputPath, logPath, f\"data_{int(time.time())}.log\")\n",
    "BrianHF.generate_YarpDvs(spikeTimeStamps, spikeIndices, neuronsGrid, filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "419f1ae4",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "if GenerateOutputVisuals:\n",
    "    \n",
    "    print(\"Generating Frames for Output...\", end=' ')\n",
    "    #outputFrames = BrianHF.generate_frames(SpikeMon_Neurons.t/ms, SpikeMon_Neurons.i, grid_width, grid_height, num_neurons=N_Neurons)\n",
    "    outputFrames = BrianHF.generate_frames(spikeTimeStamps, spikeIndices, grid_width, grid_height, num_neurons=N_Neurons)\n",
    "    print(\"Output Frames Generation Complete.\")\n",
    "    videoTime = spikeTimeStamps[-1] if len(spikeTimeStamps) > 0 else simTime\n",
    "    print(f\"Video Time: {videoTime}\")\n",
    "    \n",
    "    del spikeTimeStamps, spikeIndices\n",
    "    gc.collect()\n",
    "    \n",
    "    \n",
    "    # Save the frames\n",
    "    if SaveNumpyFrames:\n",
    "        print(\"Saving Input Frames as Numpy Arrays...\")\n",
    "        filename = os.path.join(resultPath, 'numpyFrames', outputStr+'.npy')\n",
    "        if os.path.exists(filename):\n",
    "            filename = os.path.join(resultPath, 'numpyFrames', f\"{outputStr}_{int(time.time())}.npy\")\n",
    "        np.save(filename, outputFrames)\n",
    "        print(\"Output Numpy Array Saved.\")\n",
    "\n",
    "\n",
    "    # Generate the GIFs from the frames\n",
    "    if GenerateGIFs:\n",
    "        print(\"Generating Input GIFs...\")\n",
    "        filename = os.path.join(resultPath, 'gifs', outputStr+'.gif')\n",
    "        if os.path.exists(filename):\n",
    "            filename = os.path.join(resultPath, 'gifs', f\"{outputStr}_{int(time.time())}.gif\")\n",
    "        BrianHF.generate_gif(outputFrames, filename, simTime, replicateDuration=True, duration=1e-8)\n",
    "        print(\"Output GIF Generation Complete.\")\n",
    "\n",
    "\n",
    "    # Generate the Videos from the frames\n",
    "    if GenerateVideos:\n",
    "        print(\"Generating Videos...\")\n",
    "        filename = os.path.join(resultPath, 'videos', outputStr+'.mp4')\n",
    "        if os.path.exists(filename):\n",
    "            filename = os.path.join(resultPath, 'videos', f\"{outputStr}_{int(time.time())}.mp4\")\n",
    "        BrianHF.generate_video(outputFrames, filename, videoTime)\n",
    "        print(\"Output Video Generation Complete.\")\n",
    "\n",
    "    del outputFrames"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "formats": "ipynb,py"
  },
  "kernelspec": {
   "display_name": "IIT",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
