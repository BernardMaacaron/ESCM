{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import glob\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from skimage.metrics import structural_similarity as ssim,\\\n",
    "                             mean_squared_error as mse,\\\n",
    "                             normalized_root_mse as nrmse,\\\n",
    "                             normalized_mutual_information as nmi\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the ERO-SNN folder and add it to the python path\n",
    "current_dir = os.getcwd()\n",
    "\n",
    "while os.path.basename(current_dir) != 'ERO-SNN':\n",
    "    print(os.path.basename(current_dir))\n",
    "    current_dir = os.path.dirname(current_dir)\n",
    "    \n",
    "print(f\"Found ERO-SNN folder: {current_dir}\")\n",
    "sys.path.append(current_dir)\n",
    "os.chdir(current_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extracting the data\n",
    "datasets = ['h36m', 'EyeTracking', 'MVSEC']\n",
    "datasets = ['h36m', 'MVSEC']\n",
    "\n",
    "Number_of_Neighbours = [4, 8, 12, 20]\n",
    "data_path = \"Meshed Videos\"\n",
    "video_batches = {}\n",
    "for dataset in datasets:\n",
    "    video_batches[dataset] = {}\n",
    "    for filename in os.listdir(data_path):\n",
    "        if filename.startswith(dataset):\n",
    "            print(f\"Found {filename} in {dataset}\")\n",
    "            input_path = os.path.join(data_path, filename, \"input-out.mp4\")\n",
    "            eros_path = os.path.join(data_path, filename, \"eros-out.mp4\")\n",
    "            for neighbours in Number_of_Neighbours:\n",
    "                scm_path = os.path.join(data_path, filename, f\"N{neighbours}\", \"scm-out.mp4\")\n",
    "                video_batches[dataset][neighbours] = [input_path, eros_path, scm_path] \n",
    "                print(f\"Found {len(video_batches[dataset][neighbours])} files for {dataset} with {neighbours} neighbours\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = {dataset: {neighbours:{} for neighbours in Number_of_Neighbours} for dataset in datasets}\n",
    "\n",
    "generate_scores = {'ssim_scores': True, 'mse_scores': False, 'nmse_scores': False, 'nmi_scores': True}\n",
    "\n",
    "for dataset in datasets:\n",
    "    for neighbours in Number_of_Neighbours:\n",
    "        eros_path = video_batches[dataset][neighbours][1]\n",
    "        scm_path = video_batches[dataset][neighbours][2]\n",
    "        input_path = video_batches[dataset][neighbours][0]\n",
    "        print(f\"Dataset: {dataset}, Neighbours: {neighbours}\")\n",
    "        print(f\"Processing combination:\\n Input: {input_path},\\n EROS: {eros_path},\\n SCM: {scm_path}\\n\")\n",
    "\n",
    "        # Load videos\n",
    "        input_video = cv2.VideoCapture(input_path)\n",
    "        eros_video = cv2.VideoCapture(eros_path)\n",
    "        scm_video = cv2.VideoCapture(scm_path)\n",
    "\n",
    "        # Check if the videos are the same length and frame rate\n",
    "        input_fps = input_video.get(cv2.CAP_PROP_FPS)\n",
    "        eros_fps = eros_video.get(cv2.CAP_PROP_FPS)\n",
    "        scm_fps = scm_video.get(cv2.CAP_PROP_FPS)\n",
    "        \n",
    "        input_frames = input_video.get(cv2.CAP_PROP_FRAME_COUNT)\n",
    "        eros_frames = eros_video.get(cv2.CAP_PROP_FRAME_COUNT)\n",
    "        scm_frames = scm_video.get(cv2.CAP_PROP_FRAME_COUNT)\n",
    "\n",
    "        print(f\"Input FPS: {input_fps}, EROS FPS: {eros_fps}, SCM FPS: {scm_fps}\")\n",
    "        print(f\"Input Frames: {input_frames}, EROS Frames: {eros_frames}, SCM Frames: {scm_frames}\")\n",
    "        continue\n",
    "        ssim_scores = {'Input-EROS': [], 'EROS-SCM': [], 'Input-SCM': []}\n",
    "        mse_scores = {'Input-EROS': [], 'EROS-SCM': [], 'Input-SCM': []}\n",
    "        nmse_scores = {'Input-EROS': [], 'EROS-SCM': [], 'Input-SCM': []}\n",
    "        nmi_scores = {'Input-EROS': [], 'EROS-SCM': [], 'Input-SCM': []}\n",
    "\n",
    "        frame_index = 0\n",
    "        while True:\n",
    "            # Read frames from all videos\n",
    "            ret1, frame1 = input_video.read()\n",
    "            ret2, frame2 = eros_video.read()\n",
    "            ret3, frame3 = scm_video.read()\n",
    "\n",
    "            # Break the loop if any video ends\n",
    "            if not ret1 or not ret2 or not ret3:\n",
    "                break\n",
    "\n",
    "            # Check if frames are in sync by comparing frame indices\n",
    "            input_frame_idx = input_video.get(cv2.CAP_PROP_POS_FRAMES)\n",
    "            eros_frame_idx = eros_video.get(cv2.CAP_PROP_POS_FRAMES)\n",
    "            scm_frame_idx = scm_video.get(cv2.CAP_PROP_POS_FRAMES)\n",
    "\n",
    "            if not (input_frame_idx == eros_frame_idx == scm_frame_idx == frame_index + 1):\n",
    "                print(f\"Error: Frames are out of sync at frame {frame_index}.\")\n",
    "                print(f\"Input Frame Index: {input_frame_idx}, EROS Frame Index: {eros_frame_idx}, SCM Frame Index: {scm_frame_idx}\")\n",
    "                break\n",
    "\n",
    "            frame_index += 1\n",
    "\n",
    "            # Convert frames to grayscale\n",
    "            gray1 = cv2.cvtColor(frame1, cv2.COLOR_BGR2GRAY)\n",
    "            gray2 = cv2.cvtColor(frame2, cv2.COLOR_BGR2GRAY)\n",
    "            gray3 = cv2.cvtColor(frame3, cv2.COLOR_BGR2GRAY)\n",
    "            \n",
    "            # # Apply binary threshold to convert to black and white\n",
    "            # _, bw1 = cv2.threshold(gray1, 254, 255, cv2.THRESH_BINARY)\n",
    "            # _, bw2 = cv2.threshold(gray2, 254, 255, cv2.THRESH_BINARY)\n",
    "            # _, bw3 = cv2.threshold(gray3, 254, 255, cv2.THRESH_BINARY)\n",
    "            \n",
    "            bw1 = gray1\n",
    "            bw2 = gray2\n",
    "            bw3 = gray3\n",
    "\n",
    "            # Compute SSIM between the two frames and append to the list\n",
    "            if generate_scores['ssim_scores']:\n",
    "                # ssim12, _ = ssim(bw1, bw2, full=True, data_range=255, use_sample_covariance=False, gaussian_weights=True, sigma=1.5)\n",
    "                # ssim23, _ = ssim(bw2, bw3, full=True, data_range=255, use_sample_covariance=False, gaussian_weights=True, sigma=1.5)\n",
    "                # ssim13, _ = ssim(bw1, bw3, full=True, data_range=255, use_sample_covariance=False, gaussian_weights=True, sigma=1.5)\n",
    "                ssim12 = ssim(bw1, bw2)\n",
    "                ssim23 = ssim(bw2, bw3)\n",
    "                ssim13 = ssim(bw1, bw3)\n",
    "                ssim_scores['Input-EROS'].append(ssim12)\n",
    "                ssim_scores['EROS-SCM'].append(ssim23)            \n",
    "                ssim_scores['Input-SCM'].append(ssim13)\n",
    "            \n",
    "            # Compute MSE between the frames and append to the list\n",
    "            if generate_scores['mse_scores']:\n",
    "                mse12 = mse(bw1, bw2)\n",
    "                mse23 = mse(bw2, bw3)\n",
    "                mse13 = mse(bw1, bw3)\n",
    "                mse_scores['Input-EROS'].append(mse12)\n",
    "                mse_scores['EROS-SCM'].append(mse23)            \n",
    "                mse_scores['Input-SCM'].append(mse13)\n",
    "\n",
    "            # Compute NMSE between the frames and append to the list\n",
    "            if generate_scores['nmse_scores']:\n",
    "                denom12 = np.sqrt(mse(bw1, bw1))\n",
    "                denom23 = np.sqrt(mse(bw2, bw2))\n",
    "                denom13 = np.sqrt(mse(bw3, bw3))\n",
    "                \n",
    "                if denom12 != 0:\n",
    "                    nmse12 = nrmse(bw1, bw2)\n",
    "                else:\n",
    "                    nmse12 = float('inf')  # or some predefined value\n",
    "\n",
    "                if denom23 != 0:\n",
    "                    nmse23 = nrmse(bw2, bw3)\n",
    "                else:\n",
    "                    nmse23 = float('inf')  # or some predefined value\n",
    "\n",
    "                if denom13 != 0:\n",
    "                    nmse13 = nrmse(bw1, bw3)\n",
    "                else:\n",
    "                    nmse13 = float('inf')  # or some predefined value\n",
    "\n",
    "                nmse_scores['Input-EROS'].append(nmse12)\n",
    "                nmse_scores['EROS-SCM'].append(nmse23)\n",
    "                nmse_scores['Input-SCM'].append(nmse13)\n",
    "            \n",
    "            # Compute NMI between the frames and append to the list\n",
    "            if generate_scores['nmi_scores']:\n",
    "                nmi12 = nmi(bw1, bw2)\n",
    "                nmi23 = nmi(bw2, bw3)\n",
    "                nmi13 = nmi(bw1, bw3)\n",
    "                nmi_scores['Input-EROS'].append(nmi12)\n",
    "                nmi_scores['EROS-SCM'].append(nmi23)\n",
    "                nmi_scores['Input-SCM'].append(nmi13)\n",
    "            \n",
    "        # Release video captures\n",
    "        input_video.release()\n",
    "        eros_video.release()\n",
    "        scm_video.release()\n",
    "        \n",
    "        # Create dataframes\n",
    "        if generate_scores['ssim_scores']:\n",
    "            results[dataset][neighbours]['ssim_scores'] = pd.DataFrame(ssim_scores)\n",
    "        if generate_scores['mse_scores']:\n",
    "            results[dataset][neighbours]['mse_scores'] = pd.DataFrame(mse_scores)\n",
    "        if generate_scores['nmse_scores']:\n",
    "            results[dataset][neighbours]['nmse_scores'] = pd.DataFrame(nmse_scores)\n",
    "        if generate_scores['nmi_scores']:\n",
    "            results[dataset][neighbours]['nmi_scores'] = pd.DataFrame(nmi_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a directory to save the results\n",
    "output_dir = 'quantitative_results'\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# Iterate through the results dictionary and save each DataFrame to a CSV file\n",
    "for dataset_name, neighbors_dict in results.items():\n",
    "    for n_neighbors, scores_dict in neighbors_dict.items():\n",
    "        for score_type, df in scores_dict.items():\n",
    "            # Define the filename\n",
    "            filename = f\"{dataset_name}_NN_{n_neighbors}_{score_type}.csv\"\n",
    "            filepath = os.path.join(output_dir, filename)\n",
    "            \n",
    "            # Save the DataFrame to a CSV file\n",
    "            df.to_csv(filepath, index=False)\n",
    "            print(f\"Saved {filepath}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Directory where the CSV files are saved\n",
    "output_dir = 'quantitative_results'\n",
    "\n",
    "# List of score types\n",
    "# score_types = ['ssim_scores', 'mse_scores', 'nmse_scores', 'nmi_scores']\n",
    "# score_types = score_types[generate_scores.values()]\n",
    "\n",
    "# DataFrame to store the statistics\n",
    "stats_df = pd.DataFrame(columns=['Dataset', 'Neighbors', 'Score Type', 'Column', 'Mean', 'Std Dev', 'Min', 'Max'])\n",
    "\n",
    "# Iterate through the CSV files in the directory\n",
    "for filename in os.listdir(output_dir):\n",
    "    if filename.endswith('scores.csv'):\n",
    "        # Extract dataset name, number of neighbors, and score type from the filename\n",
    "        parts = filename.split('_')\n",
    "        dataset_name = parts[0]\n",
    "        n_neighbors = parts[2]\n",
    "        score_type = parts[3].split('.')[0]\n",
    "        \n",
    "        # Read the CSV file into a DataFrame\n",
    "        filepath = os.path.join(output_dir, filename)\n",
    "        df = pd.read_csv(filepath)\n",
    "        \n",
    "        # Compute statistics\n",
    "        mean_values = df.mean()\n",
    "        std_values = df.std()\n",
    "        min_values = df.min()\n",
    "        max_values = df.max()\n",
    "        \n",
    "        # Create a temporary DataFrame to hold the statistics for the current file\n",
    "        temp_df = pd.DataFrame({\n",
    "            'Dataset': dataset_name,\n",
    "            'Neighbors': n_neighbors,\n",
    "            'Score Type': score_type,\n",
    "            'Column': df.columns,\n",
    "            'Mean': mean_values.values,\n",
    "            'Std Dev': std_values.values,\n",
    "            'Min': min_values.values,\n",
    "            'Max': max_values.values\n",
    "        })\n",
    "        \n",
    "        # Concatenate the temporary DataFrame with the main stats_df\n",
    "        stats_df = pd.concat([stats_df, temp_df], ignore_index=True)\n",
    "        \n",
    "        # Generate a plot for the DataFrame\n",
    "        plt.figure(figsize=(10, 6))\n",
    "        for column in df.columns:\n",
    "            plt.plot(df[column], label=column)\n",
    "        \n",
    "        score_type = score_type.upper()\n",
    "        plt.title(f'{score_type} scores for {dataset_name} with k = {n_neighbors}')\n",
    "        plt.xlabel('Frame')\n",
    "        plt.ylabel(score_type)\n",
    "        plt.legend()\n",
    "        plt.grid(True)\n",
    "        \n",
    "        # Save the plot\n",
    "        plot_filename = f\"{dataset_name}_NN_{n_neighbors}_{score_type}.png\"\n",
    "        plot_filepath = os.path.join(output_dir, plot_filename)\n",
    "        plt.savefig(plot_filepath)\n",
    "        plt.close()\n",
    "        \n",
    "        print(f\"Saved plot {plot_filepath}\")\n",
    "\n",
    "# Save the statistics DataFrame to a CSV file\n",
    "stats_filepath = os.path.join(output_dir, 'statistics_summary.csv')\n",
    "stats_df.to_csv(stats_filepath, index=False)\n",
    "print(f\"Saved statistics summary to {stats_filepath}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dir = 'quantitative_results'\n",
    "stat_sum = pd.read_csv(os.path.join(output_dir, 'statistics_summary.csv'))\n",
    "\n",
    "# Drop nmse_scores\n",
    "stat_sum = stat_sum[stat_sum['Score Type'] != 'nmse']\n",
    "# display(stat_sum)\n",
    "\n",
    "grouped = stat_sum.groupby(['Dataset', 'Neighbors', 'Score Type', 'Column']).mean()\n",
    "display(grouped)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "2.7.undefined"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
