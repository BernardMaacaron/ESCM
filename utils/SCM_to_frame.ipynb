{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73517df4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import json\n",
    "import os\n",
    "import numpy as np\n",
    "import sys\n",
    "import glob\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import bisect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c7ed33f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the ERO-SNN folder and add it to the python path\n",
    "current_dir = os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edee6ffe",
   "metadata": {},
   "outputs": [],
   "source": [
    "while os.path.basename(current_dir) != 'ERO-SNN':\n",
    "    print(os.path.basename(current_dir))\n",
    "    current_dir = os.path.dirname(current_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2036f837",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Found ERO-SNN folder: {current_dir}\")\n",
    "sys.path.append(current_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d3df152",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "import BrianHF\n",
    "from datasets.utils.parsing import import_yarp_skeleton_data, batchIterator\n",
    "from datasets.utils.events_representation import EROS\n",
    "from datasets.utils.export import ensure_location, str2bool #, get_movenet_keypoints, get_center\n",
    "from bimvee.importIitYarp import importIitYarp as import_dvs\n",
    "from bimvee.importAe import importAe\n",
    "from bimvee.importIitYarp import importIitYarpBinaryDataLog"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b7169cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_ts_list(frame_length, frame_interval, ts):\n",
    "    out = {'ts': []}\n",
    "    \n",
    "    # Create a list of timestamps starting from ts[0] and incrementing by 30ms\n",
    "    x = np.arange(ts[0], ts[-1], frame_interval / 1000.0)\n",
    "    \n",
    "    # Convert ts to a NumPy array for faster operations\n",
    "    ts = np.array(ts)\n",
    "    \n",
    "    for start_time in tqdm(x, desc=\"Processing time windows\"):\n",
    "        # Create a window of frame_length ms\n",
    "        end_time = start_time + frame_length / 1000.0\n",
    "        \n",
    "        # Use binary search to find the indices of the timestamps within the window\n",
    "        start_idx = bisect.bisect_left(ts, start_time)\n",
    "        end_idx = bisect.bisect_right(ts, end_time)\n",
    "        \n",
    "        # Collect all timestamps within this window\n",
    "        window_ts = ts[start_idx:end_idx]\n",
    "        out['ts'].extend(window_ts)\n",
    "    \n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9beb6d50",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def process(data_dvs_file, output_path, skip=None, args=None):\n",
    "\n",
    "    if skip == None:\n",
    "        skip = 1\n",
    "    else:\n",
    "        skip = int(skip) + 1\n",
    "\n",
    "    print('Importing file...', data_dvs_file)\n",
    "    data_dvs = importAe(filePathOrName=data_dvs_file)\n",
    "    print('File imported.')\n",
    "\n",
    "        \n",
    "    data_dvs = next(BrianHF.find_keys(data_dvs, 'dvs'))\n",
    "    data_ts = create_ts_list(args['frame_length'], args['interval_length'], data_dvs['ts'])\n",
    "    \n",
    "    print(f\"{data_dvs_file.split('/')[-3]}: \\n start: {(-1)*data_dvs['tsOffset']} \\n duration: {data_dvs['ts'][-1]} \\n scaled duration: {data_ts['ts'][-1]}\")\n",
    "    iterator = batchIterator(data_dvs, data_ts)\n",
    "    \n",
    "    frame_width = np.max(data_dvs['x'])+1\n",
    "    frame_height = np.max(data_dvs['y'])+1\n",
    "    \n",
    "    # Calculate fps based on the number of frames and total duration\n",
    "    total_duration = data_dvs['ts'][-1] - data_dvs['ts'][0]\n",
    "    num_frames = len(data_ts['ts'])\n",
    "\n",
    "    args['fps'] = int(min(num_frames / total_duration, 1024))\n",
    "    print(f\"FPS: {args['fps']}\")\n",
    "\n",
    "    \n",
    "    if args['write_video']:\n",
    "        output_path_video = os.path.join(output_path,'scm-out.mp4')\n",
    "        print(output_path_video)\n",
    "        video_out = cv2.VideoWriter(output_path_video, cv2.VideoWriter_fourcc('M', 'J', 'P', 'G'), args['fps'],\n",
    "                                    (frame_width, frame_height))\n",
    "\n",
    "    for fi, (events, pose, batch_size) in enumerate(iterator):\n",
    "        sys.stdout.write(f'frame: {fi}/{len(data_ts[\"ts\"])}\\r')\n",
    "        sys.stdout.flush()\n",
    "        # old_vx = None\n",
    "        # old_vy = None\n",
    "\n",
    "        frame = np.zeros((frame_height, frame_width), dtype=np.uint8)\n",
    "\n",
    "\n",
    "        for ei in range(batch_size):                \n",
    "            vx=int(events['x'][ei])\n",
    "            vy=int(events['y'][ei])\n",
    "            \n",
    "                \n",
    "            frame[vy,vx] = 255\n",
    "        \n",
    "            \n",
    "        if fi % skip != 0:\n",
    "            continue\n",
    "\n",
    "        filename = os.path.basename(data_dvs_file)\n",
    "        \n",
    "        if args['write_images']:\n",
    "            cv2.imwrite(os.path.join(output_path, f'{filename}_{fi:04d}.jpg'), frame)\n",
    "        if args['write_video']:\n",
    "            framergb = cv2.cvtColor(frame, cv2.COLOR_GRAY2BGR)\n",
    "            video_out.write(frame)\n",
    "\n",
    "    if args['write_video']:\n",
    "        video_out.release()\n",
    "\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dd10e86",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    # Define the variables directly\n",
    "    eros_kernel = 8\n",
    "    gauss_kernel = 7\n",
    "    skip_image = None\n",
    "    input_data_dir = 'SimulationResultsFinal'\n",
    "    output_base_path = 'EROS_like'\n",
    "    write_images = False\n",
    "    write_video = True\n",
    "    frame_length = 1.1 #ms\n",
    "    interval_length = 30 #ms\n",
    "    fps = interval_length/frame_length\n",
    "    dev = False\n",
    "    ts_scaler = 1.0\n",
    "    \n",
    "    # Ensure the base output path exists\n",
    "    output_base_path = os.path.abspath(output_base_path)\n",
    "    ensure_location(output_base_path)\n",
    "    input_data_dir = os.path.abspath(input_data_dir)\n",
    "    \n",
    "    datasets = ['EyeTracking', 'h36m_sample', 'MVSEC_short_outdoor']\n",
    "\n",
    "    # Create a dictionary to hold the arguments\n",
    "    args = {\n",
    "        'eros_kernel': eros_kernel,\n",
    "        'gauss_kernel': gauss_kernel,\n",
    "        'write_images': write_images,\n",
    "        'write_video': write_video,\n",
    "        'frame_length': frame_length,\n",
    "        'interval_length': interval_length,\n",
    "        'fps': fps,\n",
    "        'dev': dev,\n",
    "        'ts_scaler': ts_scaler\n",
    "        }\n",
    "    \n",
    "    # input_data_dir = os.path.join(input_data_dir, dataset)\n",
    "    log_files = []\n",
    "    h36m = glob.glob(os.path.join(input_data_dir, '**/cam2_S1_Directions/ch0dvs/YarpSpikeLog/**/data.log'), recursive=True)\n",
    "    EyeTracking = glob.glob(os.path.join(input_data_dir, '**/user_5_1/ch0dvs_old/YarpSpikeLog/**/data.log'), recursive=True)\n",
    "    MVSEC = glob.glob(os.path.join(input_data_dir, '**/MVSEC_short_outdoor/YarpSpikeLog/**/data.log'), recursive=True)\n",
    "    \n",
    "    log_files.extend(h36m)\n",
    "    log_files.extend(EyeTracking)\n",
    "    log_files.extend(MVSEC)\n",
    "    \n",
    "    print(log_files)\n",
    "    \n",
    "    for log_file in log_files:\n",
    "        # Create a corresponding output path\n",
    "        relative_path = os.path.relpath(log_file, input_data_dir)\n",
    "        output_path = os.path.join(output_base_path, os.path.dirname(relative_path))\n",
    "        ensure_location(output_path)\n",
    "\n",
    "        print(\"Processing:\", log_file)\n",
    "        print(\"Output path:\", output_path)\n",
    "\n",
    "\n",
    "        if process(log_file, output_path, skip=skip_image, args=args):\n",
    "            print(f\"Processed {log_file}\")\n",
    "        else:\n",
    "            print(f\"Error processing {log_file}\")  \n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  },
  "kernelspec": {
   "display_name": "IIT",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
