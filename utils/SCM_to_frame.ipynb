{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21dfefb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import json\n",
    "import os\n",
    "import numpy as np\n",
    "import sys\n",
    "import glob\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c0a89e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the ERO-SNN folder and add it to the python path\n",
    "current_dir = os.getcwd()\n",
    "\n",
    "while os.path.basename(current_dir) != 'ERO-SNN':\n",
    "    print(os.path.basename(current_dir))\n",
    "    current_dir = os.path.dirname(current_dir)\n",
    "    \n",
    "print(f\"Found ERO-SNN folder: {current_dir}\")\n",
    "sys.path.append(current_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cc71360",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "import BrianHF\n",
    "from datasets.utils.parsing import import_yarp_skeleton_data, batchIterator\n",
    "from datasets.utils.events_representation import EROS\n",
    "from datasets.utils.export import ensure_location, str2bool #, get_movenet_keypoints, get_center\n",
    "from bimvee.importIitYarp import importIitYarp as import_dvs\n",
    "from bimvee.importAe import importAe\n",
    "from bimvee.importIitYarp import importIitYarpBinaryDataLog"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08c1e526",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def create_ts_list(fps,ts):\n",
    "    out = dict()\n",
    "    out['ts'] = list()\n",
    "    x = np.arange(ts[0],ts[-1],1/fps)\n",
    "    for i in x:\n",
    "        out['ts'].append(i)\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39121145",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def process(data_dvs_file, output_path, skip=None, args=None):\n",
    "\n",
    "    if skip == None:\n",
    "        skip = 1\n",
    "    else:\n",
    "        skip = int(skip) + 1\n",
    "\n",
    "    print('Importing file...', data_dvs_file)\n",
    "    data_dvs = importAe(filePathOrName=data_dvs_file)\n",
    "    print('File imported.')\n",
    "\n",
    "        \n",
    "    data_dvs = next(BrianHF.find_keys(data_dvs, 'dvs'))\n",
    "    data_ts = create_ts_list(args['fps'],data_dvs['ts'])\n",
    "    \n",
    "    print(f\"{data_dvs_file.split('/')[-3]}: \\n start: {(-1)*data_dvs['tsOffset']} \\n duration: {data_dvs['ts'][-1]}\")\n",
    "    iterator = batchIterator(data_dvs, data_ts)\n",
    "    \n",
    "    frame_width = np.max(data_dvs['x'])+1\n",
    "    frame_height = np.max(data_dvs['y'])+1\n",
    "    \n",
    "\n",
    "    \n",
    "    poses_movenet = []\n",
    "    if args['write_video']:\n",
    "        output_path_video = os.path.join(output_path,'scm-out.mp4')\n",
    "        print(output_path_video)\n",
    "        video_out = cv2.VideoWriter(output_path_video, cv2.VideoWriter_fourcc('M', 'J', 'P', 'G'), args['fps'],\n",
    "                                    (frame_width, frame_height))\n",
    "\n",
    "    for fi, (events, pose, batch_size) in enumerate(iterator):\n",
    "        sys.stdout.write(f'frame: {fi}/{len(data_ts[\"ts\"])}\\r')\n",
    "        sys.stdout.flush()\n",
    "        # old_vx = None\n",
    "        # old_vy = None\n",
    "\n",
    "        frame = np.zeros((frame_height, frame_width), dtype=np.uint8)\n",
    "\n",
    "        # if args['dev']:\n",
    "        #     print('frame: ', fi)\n",
    "        for ei in range(batch_size):                \n",
    "            vx=int(events['x'][ei])\n",
    "            vy=int(events['y'][ei])\n",
    "            \n",
    "            # if old_vx is None and old_vy is None:\n",
    "            #     old_vx = vx\n",
    "            #     old_vy = vy\n",
    "            # else:\n",
    "            #     frame[old_vx,old_vy] = 0\n",
    "            #     old_vx = vx\n",
    "            #     old_vy = vy\n",
    "                \n",
    "            frame[vy,vx] = 255\n",
    "        \n",
    "            \n",
    "        if fi % skip != 0:\n",
    "            continue\n",
    "\n",
    "        # frame = cv2.GaussianBlur(frame, (args['gauss_kernel'], args['gauss_kernel']), 0)\n",
    "\n",
    "        filename = os.path.basename(data_dvs_file)\n",
    "        \n",
    "        if args['write_images']:\n",
    "            cv2.imwrite(os.path.join(output_path, f'{filename}_{fi:04d}.jpg'), frame)\n",
    "        if args['write_video']:\n",
    "            framergb = cv2.cvtColor(frame, cv2.COLOR_GRAY2BGR)\n",
    "            video_out.write(framergb)\n",
    "\n",
    "    if args['write_video']:\n",
    "        video_out.release()\n",
    "\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e65f799f",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def main():\n",
    "    # Define the variables directly\n",
    "    eros_kernel = 8\n",
    "    # frame_width = 640\n",
    "    # frame_height = 480\n",
    "    gauss_kernel = 7\n",
    "    skip_image = None\n",
    "    input_data_dir = 'SimulationResultsFinal'\n",
    "    output_base_path = 'EROS_like'\n",
    "    write_images = False\n",
    "    write_video = True\n",
    "    frame_length = 30 #ms\n",
    "    interval_length = 1000 #ms\n",
    "    fps = interval_length/frame_length\n",
    "    dev = False\n",
    "    ts_scaler = 1.0\n",
    "    \n",
    "    # Ensure the base output path exists\n",
    "    output_base_path = os.path.abspath(output_base_path)\n",
    "    ensure_location(output_base_path)\n",
    "    input_data_dir = os.path.abspath(input_data_dir)\n",
    "    \n",
    "    datasets = ['DHP19_Sample', 'EyeTracking', 'h36m_sample', 'MVSEC_short_outdoor']\n",
    "    datasets = ['h36m_sample', 'MVSEC_short_outdoor']\n",
    "\n",
    "    for dataset in datasets:\n",
    "        input_data_dir = os.path.join(input_data_dir, dataset)\n",
    "        # Iterate over .log files in the input data directory\n",
    "        log_files = glob.glob(os.path.join(input_data_dir, '**/data.log'), recursive=True)\n",
    "        for log_file in log_files:\n",
    "            try:\n",
    "                # Create a corresponding output path\n",
    "                relative_path = os.path.relpath(log_file, input_data_dir)\n",
    "                output_path = os.path.join(output_base_path, dataset, os.path.dirname(relative_path))\n",
    "                ensure_location(output_path)\n",
    "\n",
    "                print(\"Processing:\", log_file)\n",
    "                print(\"Output path:\", output_path)\n",
    "\n",
    "                # Create a dictionary to hold the arguments\n",
    "                args = {\n",
    "                    'eros_kernel': eros_kernel,\n",
    "                    # 'frame_width': frame_width,\n",
    "                    # 'frame_height': frame_height,\n",
    "                    'gauss_kernel': gauss_kernel,\n",
    "                    'write_images': write_images,\n",
    "                    'write_video': write_video,\n",
    "                    'fps': fps,\n",
    "                    'dev': dev,\n",
    "                    'ts_scaler': ts_scaler\n",
    "                }\n",
    "                process(log_file, output_path, skip=skip_image, args=args)\n",
    "            except:\n",
    "                print(f\"Error processing {log_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b9aa6a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
